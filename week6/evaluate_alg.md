<script type="text/javascript" 
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>

<span style="color:pink">*이 글은 Coursera에서 Andrew Ng 교수님의 머신러닝 강의를 듣고 읽기 자료를 읽으면서 복습차원에서 개인적으로 요약한 글입니다.*<span>

# Evaluating a Learning Algorithm

## 가설의 평가
머신 러닝 알고리즘의 가설을 설정하고 이를 훈련시킨 후 그 가설이 적합한지 확인을 해야 한다. 피쳐의 수가 적어서 가설을 3차원 이하의 그래프로 표현할 수 있다면 데이터에 대한 가설의 모습을 시각적으로 확인할 수 있지만 실제 머신 러닝 문제에서는 수백 ~ 수만 개의 피쳐가 있기 때문에 이를 시각적으로 표현할 수가 없다. 따라서 과적합이나 과소적합 등의 문제를 시각적으로 평가할 수 없기 때문에 이를 평가할 다른 방법이 필요하게 된다. 이러한 평가를 통해 현재 모델에서 regularization의 정도를 증가/감소시킬지, 피쳐의 수를 증가/감소시키든지, 데이터를 더 수집할 것인지 등의 모델 개선을 선택할 수 있을 것이다.

가설을 평가할 수 있는 좋은 방법으로 기존의 데이터 셋을 훈련 세트와 학습 세트로 나누는 방법이 있다. 모델에서 과적합이 발생한다는 것은 훈련에 사용되지 않은 새로운 입력 값에 대하여 원하는 예측이 되지 않는다는 것에 착안하여 기존의 데이터 셋에서 일부만 훈련에 참여하고 나머지 일부는 테스트를 해서 훈련 데이터의 예측률은 높은데 테스트의 예측률이 높지 않다면 과적합으로 판단하고 훈련 데이터의 예측률 또한 낮다면 과소적합으로 판단할 수 있다. 

일반적으로 데이터 셋을 섞어서 70%는 훈련 셋으로 사용하고 30%는 테스트 셋으로 사용한다. 각 모델의 예측률은 선형 회귀의 경우 간단하게 $J(\theta)$의 값으로 체크할 수 있고 분류 문제의 경우 실제 라벨값과 예측 라벨값이 몇 개나 다른지를 전체 데이터 개수 중에서의 퍼센트로 표현하려 에러율을 나타낼 수 있다. 강의에서는 misclassification error라고 해서 이진 로지스틱 회귀에서 테스트 셋의 라벨 에러율을 계산하는 법을 따로 설명해주고 있는데 다음과 같다.

입력 데이터 x와 실제 라벨 y에 대하여

$err(h\theta(x), y)=
\begin{cases}
1 &((h_\theta(x)\ge0.5 \And y=0) or (h_\theta(x)<0.5\And y=1) ) \\
0 & (otherwise)
\end{cases}$

즉 테스트 셋의 에러울 퍼센트는 다음과 같다. 

Test error = ${1\over m_{test}}\sum_{i=1}^{m_{test}}err(h_\theta(x_{test}^{(i)}), y_{test}^{(i)})$

## 가설 모델의 선택 및 훈련/검증/테스트 셋
가설을 선택할 때 특성을 거듭제곱하여 다항식 가설을 만들 수도 있다. 즉 여러 개의 다항식 가설이 존재할 수 있다는 것이다. 그렇다면 어떤 다항식 가설이 가장 예측을 잘하는지 선택하기 위한 지표가 필요하다.  

강의에서는 10차식까지의 가설을 제시한다. 다음과 같다.

- $h_\theta(x) = \theta_0+\theta_1x$
- $h_\theta(x) = \theta_0+\theta_1x+\theta_2x^2$
- $h_\theta(x) = \theta_0+\theta_1x+\theta_2x^2+\theta_3x^3$\
   $\vdots$
- $h_\theta(x) = \theta_0+\theta_1x+\cdots+\theta_{10}x^{10}$

이 많은 다항식 가설들 중 어느 가설을 선택하는 기준은 무엇일까? 일단 위에서 배운 훈련/테스트 셋 분리를 통해 각 다항식 가설들의 에러율을 계산해서 5차식일 때가 가장 에러율이 낮았다고 하자. 그렇다면 5차식의 모델을 선택해도 되는 것이냐고 하면 그건 또 아니라고 한다. 가설은 여러 가지인데 이 가설들이 모두 동일한 데이터 셋에서의 훈련 셋으로 훈련을 받고 테스트 셋으로 에러율을 계산하기 때문에 테스트 셋 또한 해당 다항식의 차수에 과적합되었을 수 있다는 셈이다. 

그렇다면 어떤 식으로 모델을 선택해야 할까? 정답은 데이터 셋을 더 쪼개서 테스트를 진행하는 것이다. 이 추가적인 테스트 셋을 검증 셋(Cross validation set)이라고 부른다. 훈련/검증/테스트 셋의 일반적인 비율은 60%, 20%, 20%이다. 검증 셋은 기존의 테스트 셋의 역할을 그대로 수행한다. 먼저 훈련 셋으로 모델을 훈련하고, 검증 셋으로 모델의 에러율을 테스트하여 훈련 셋에 과적합되었는지 아닌지 체크한다. 이를 모든 모델에 관하여 진행한다. 그리고 이 중 검증 셋으로의 에러율이 가장 낮은 모델을 선택하여 최종적으로 테스트 셋을 이용해 에러율을 계산하고 이 에러율이 너무 높지는 않은지 체크한다. 해당 에러율이 높다는 것은 모델이 검증 셋에 과적합되었을 수 있다는 의미이다. 
