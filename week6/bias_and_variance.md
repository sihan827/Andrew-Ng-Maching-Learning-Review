<script type="text/javascript" 
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>

<span style="color:pink">*이 글은 Coursera에서 Andrew Ng 교수님의 머신러닝 강의를 듣고 읽기 자료를 읽으면서 복습차원에서 개인적으로 요약한 글입니다.*<span>

# Bias vs. Variance

## 편향 (Bias)과 분산 (Variance) 진단하기
머신 러닝 모델의 가설의 다항식 차수와 과적합/과소적합 간의 관계 파악을 위해 편향과 분산을 분석할 수 있다. 다음 슬라이드는 다항식 회귀를 공부할 때 과적합, 과소적합의 예를 보여주고 있다. 

![과적합, 과소적합](/week6/image/fitting.png)

슬라이드에서 볼 수 있듯이 1차식에서는 과소적합이 발생하고 4차식에서는 과적합이 발생하는 것을 알 수 있다. 그렇다면 과적합/과소적합이 발생하지 않는 차수의 모델을 찾아야 할 것이다.

과적합/과소적합을 체크하기 가장 좋은 방법은 이전 강의에서 배운 데이터 셋 스플릿이다. 훈련 셋의 에러율과 검증 셋의 에러율을 비교하면 과적합/과소적합을 쉽게 구분할 수 있다. 에러율은 회귀 방식에 따라 간단하게 비용함수를 사용해도 되고 다중 클래스의 경우 라벨값의 불일치여부를 퍼센트로 나타내는 misclassification 에러를 사용해도 된다. 에러율로 비용함수를 사용할 때에는 regularization 항은 제외하고 비용을 계산한다. 그 이유는 regularization 항 자체가 과적합을 막기 위한 추가적인 항이므로 실제 비용 평가시에는 사용하지 않는 것이라고 한다. 

이러한 에러율을 가설의 차수에 따라 훈련 셋, 검증 셋 각각으로 계산하여 그래프로 그리면 다음과 같다. (아래의 경우 에러율을 비용함수로 나타내었지만 misclassification 에러도 비슷한 그래프가 그려질 것이다.)

![차수에 따른 에러율](/week6/image/polynomial_plot.png)

차수가 작을 때에는 훈련 셋의 에러율 $J_{train}(\theta)$와 검증 셋의 에러율 $J_{cv}(\theta)$ 둘다 상당히 높다. 이는 과소적합이기 때문인데 이 때 편향이 크다고 표현한다. 전혀 학습이 되지 않은 상태인 셈이다.\
차수가 점차 증가할수록 훈련 데이터에 알맞게 모델이 학습되므로 $J_{train}(\theta)$, $J_{cv}(\theta)$는 점차 감소하게 된다. 그러다가 어느 순간부터 
$J_{train}(\theta)$는 계속 감소하는데 $J_{cv}(\theta)$는 증가하게 된다. 즉 과적합이 발생하여 모델이 훈련 셋에만 치중되어 학습된 것이므로 검증 셋에 대하여 높은 에러율이 발생하게 된다. 이 때 분산이 크다고 표현한다. 모델이 훈련 셋에만 치중되어 학습된 상태인 셈이다. 따라서 $J_{cv}(\theta)$의 최소치에서의 차수의 가설을 선택하는 것이 과적합/과소적합이 없는 가장 합리적인 선택이다. 이후 테스트 셋을 통해 검증 셋에 과적합되지 않았는지 추가로 확인하면 될 것이다. 

## Regularization에서의 편향 (Bias)과 분산 (Variance) 진단하기
위에서는 다항식 가설의 차수에 따른 에러율을 분석하였는데 이번에는 regularization의 파라미터 $\lambda$에 따른 에러율을 분석한다고 한다. 예를 들어서 위의 차수에 따른 에러율 분석에서 차수가 4일 때 검증 셋의 에러율이 낮아서 이 가설을 선택했다고 하자. 그러면 이제 $\lambda$에 따른 에러율을 분석할 필요가 있다. 학습에 참여하는 비용함수는 regularization 항이 존재하므로 $\lambda$에 따라 에러율이 달라질 것이다. 반면에 평가를 위해 테스트 셋, 검증 셋, 훈련 셋에 대하여 측정하는 비용함수는 위에서 언급한 이유와 같은 이유로 regularization 항을 제외하고 계산한다. 

다양한 차수에 대하여 에러율을 계산한 것처럼 다양한 $\lambda$값에 대하여 에러율 그래프를 그려 보면 어느 정도의 $\lambda$값에서 과적합/과소적합이 발생하지 않는지 판단할 수 있다. 아래 슬라이드는 다양한 $\lambda$값에서 훈련 셋 에러율과 검증 셋 에러율을 구해 보고 검증 셋의 에러율이 가장 낮은 $\lambda$에 대하여 테스트 셋의 에러율을 구해 보는 과정을 보여준다. 

![람다 값 찾기](/week6/image/reg_fitting.png)

위 슬라이드처럼 $\lambda$를 0.01, 0.02, 0.04 순으로 10.24까지 증가시켜 가면서 모델을 학습하여 훈련 셋과 검증 셋의 에러율을 체크하여 검증 셋의 에러율이 가장 낮은 $\lambda$에 대하여 테스트 셋의 에러율을 체크하여 검증 셋에 과적합되지 않았는지 확인한다. 

![람다 값에 따른 그래프 플롯](/week6/image/reg_plot.png)

위 슬라이드는 훈련 셋과 검증 셋의 에러율을 $\lambda$ 값에 따라서 그래프로 그린 것이다. $\lambda$이 커질수록 regularization의 효과가 커져서 학습이 더뎌지고 $\lambda$이 작을수록 regularization의 효과가 작아져서 학습이 빠르게 진행된다. 즉 $\lambda$가 작을수록 과적합이 발생하므로 분산이 크고 $\lambda$가 클수록 과소적합이 발생하므로 편향이 크다. 따라서 검증셋의 에러율이 가장 작을 때의 $\lambda$를 선택해야 과적합/과소적합을 막을 수 있다. 

## 학습 곡선 (Learning Curve)
학습 곡선은 훈련 데이터 셋의 크기에 따른 훈련 셋 에러와 검증 셋 에러를 그래프로 그린 것이다. 이 그래프의 모습을 대략 살펴보면 다음과 같은 특징을 발견할 수 있다. 
- 데이터 셋이 적을 때에는 모델이 이에 맞추어 학습될 수 있으므로 학습 셋 에러율이 낮다. 반면에 검증 셋은 이에 맞춰지지 않았으므로 검증 셋 에러율은 크다. 
- 데이터 셋이 점차 증가할수록 모델이 이에 전부 맞추는 것은 어려우므로 훈련 셋 에러율이 증가하게 된다. 반면에 검증 셋은 어느 정도 모델에 맞춰질 수 있게 되어 검증 셋 에러율이 감소하게 된다.
  
분산이 높을 때와 편향이 높을 때 그래프를 살펴보면 차이를 발견할 수 있다.\
 먼저 편향이 높을 때는 그래프가 다음과 같이 그려진다. 

![편향이 높은 학습 곡선](/week6/image/bias_LC_plot.png)

편향이 높다는 것은 가설이 과소적합이 발생한다는 의미이므로 데이터 셋이 증가하더라도 그 데이터에 맞게 학습이 잘 이루어지지 않는다는 의미이다. 따라서 데이터 셋이 증가해도 훈련 셋과 검증 셋 모두 상당히 높은 에러율을 보여 준다. 즉 데이터 셋의 크기를 증가하더라도 크게 효과를 보지 못할 것이다.

분산이 높을 때는 그래프가 다음과 같이 그려진다. 

![분산이 높은 학습 곡선](/week6/image/variance_LC_plot.png)

분산이 높다는 것은 가설이 과적합이 발생한다는 의미이므로 데이터 셋이 증가한다면 그에 맞춰 학습이 더 이루어지므로 그래프처럼 훈련 셋 에러율은 계속 증가하고 검증 셋 에러율은 계속 감소한다. 즉 데이터 셋의 크기가 증가하게 되면 검증 셋 에러율은 계속 감소하게 될 것이므로 데이터 셋 크기를 늘리면 과적합을 해소하는 데 도움을 줄 것이다.

## 다음으로 할 것 결정하기
이제까지 배운 다양한 진단을 통해 어떤 작업이 편향/분산이 큰 가설 모델에 대하여 문제 해결에 효과적인지를 분석할 수 있다. 각 경우에 대하여 다음과 같은 조치가 유효할 수 있다.

- 큰 편향 해결하기 
  - 추가 피쳐를 찾아보기
  - 고차 다항식 피쳐를 추가하기
  - $\lambda$ 값 감소시키기
- 큰 분산 해결하기
  - 피쳐 수를 줄이기
  - 더 많은 데이터를 찾기
  - $\lambda$ 값 증가시키기

## 신경망의 모델 구조와 과적합/과소적합
신경망 또한 과적합/과소적합의 문제에 빠질 수 있다. 

![신경망](/week6/image/nn_analysis.png)

- 먼저 은닉 레이어 수가 적을 때에는 파라미터 수가 적기 때문에 과소적합이 발생할 가능성이 더 크다. 이 경우 위에서 말한 대처 방식처럼 피쳐 수를 늘리는 것이 효과적이므로 은닉 레이어를 추가시키는 것이 도움이 될 수 있다.\
- 반면 은닉 레이어 수가 많을 때에는 파라미터 수가 많으며 이는 과적합이 발생할 가능성이 크다는 것을 시사한다. 이 경우 은닉 레이어를 제거하기보다는 먼저 $\lambda$ 값을 증가시켜서 regularization의 영향을 증가시켜 보는 것이 유리하다. 

이외에도 신경망에서의 과적합을 막기 위해 다양한 연구가 진행 중이라고 한다.