<script type="text/javascript" 
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>

<span style="color:pink">*이 글은 Coursera에서 Andrew Ng 교수님의 머신러닝 강의를 듣고 읽기 자료를 읽으면서 복습차원에서 개인적으로 요약한 글입니다.*<span>

# Handling Skewed Class & Using Large Data Sets

## 편향된 클래스에 대한 에러 분석
강의에서 암 분류 문제를 예시로 들고 있다. 암이면 1, 아니면 0으로 분류하는 로지스틱 회귀 모델이다. 테스트를 해보니 테스트 셋에 대하여 에러율이 1%의 낮은 결과가 나왔다고 해보자. 에러율만 보았을 때는 매우 좋은 분류기 같지만 문제는 전체 데이터에서 0.5%의 환자만이 실제로 암이었다는 점이다. 이 경우 단순히 모든 환자를 0으로 판단하는 분류기도 에러율 0.5%라는 매우 낮은 값을 얻게 된다. 즉 에러율만으로 모델이 좋은 예측 성능을 가지는지 알 수 없다. 

이렇게 특정 클래스의 비율이 전체 클래스에 비해서 매우 작은 경우를 skewed class, 편향된 클래스라고 부른다. 이러한 클래스에 대해서는 에러율 뿐만 아니라 precision, recall이라는 추가적인 개념이 필요하다. 

강의 슬라이드의 다음 표를 보자. 

<img src="/week6/image/table.png" width="40%" height="30%" title="Table"> 

실제 클래스와 그 클래스의 분류에 따라 크게 네 가지로 나뉜다. 
1. 실제로 1인데 1이라고 예측하는 것을 true positive(TP)라고 한다. 
2. 실제로 0인데 1이라고 예측하는 것을 false positive(FP)라고 한다.
3. 실제로 1인데 0이라고 예측하는 것을 false negative(FN)라고 한다.
4. 실제로 0인데 0이 아니라고 예측하는 것을 true negative(TN)이라고 한다. 

이를 통해 precision과 recall을 정의할 수 있다.
- Precision: 1로 예측된 것들 중에서 실제로 1인 비율을 의미한다. 즉 TP/(TP+FP)이다.
- Recall: 실제로 1인 것들 중에서 정확하게 1이라고 예측된 것의 비율을 의미한다. 즉 TP/(TP+FN)이다.
  
이 둘을 조절하여 가설 모델의 에러를 잡을 수 있다. 일반적으로는 로지스틱 회귀 모델의 경계값(threshold)를 조절함으로써 이루어진다. 원래는 $h_\theta(x) \ge 0.5$이면 1로 분류하고 $h_\theta(x) < 0.5$이면 0으로 분류했으나 편향된 클래스가 있다면 이 경계값 0.5를 조절함으로써 precision과 recall을 조절할 수 있다.
- 클래스 1임이 확실할 때만 이를 예측하고 싶다면 경계값을 크게(예: 0.9) 하면 된다. 이 경우 precision이 커지고 recall이 작아지게 된다.
- 실제로 클래스 1인 것의 예측을 절대로 실패하고 싶지 않다면 경계값을 작게(예: 0.3) 하면 된다. 이 경우 recall이 커지고 precision이 작아지게 된다.

precision과 recall의 이러한 관계를 그래프로 표현하면 강의자료의 다음 그래프와 같다.

<img src="/week6/image/graph.png" width="40%" height="30%" title="Graph"> 

precision과 recall의 값은 해결해야 할 문제에 따라 다르겠지만 기본적으로는 두 값이 어느 정도는 유사해야 좋은 모델이라고 말할 수 있다고 한다. 이를 판단하기 위해 만든 평가 지표가 바로 F score($F_1$ score)이다. 식은 다음과 같다.

F score = $2PR\over {P+R}$

예를 들어 P = 0.02이고 R = 1.0인 알고리즘 1이 있다고 하면 알고리즘의 F score은 약 0.04이다. P = 0.5이고 R = 0.4인 알고리즘 2의 F score은 약 0.2이다. 알고리즘 1의 경우 항상 1로 예측하는 좋지 않은 알고리즘이므로 F score가 알고리즘 2보다 낮은 것을 볼 수 있다.

## 머신러닝을 위한 데이터셋
강의에서는 2001년에 Banko와 Brill이 한 연구에 대하여 먼저 설명하고 있다. 이들은 혼동될 수 있는 단어 구별을 위한 머신 러닝 모델을 로지스틱 회귀, Winnow, 메모리 기반, 나이브 베이즈 4개의 훈련 알고리즘으로 훈련 셋의 사이즈를 증가시켜가면서 훈련시켰는데 다음과 같은 결과가 나왔다고 한다.

<img src="/week6/image/trainsize_incr.png" width="40%" height="30%" title="Graph for Train Size"> 

모든 알고리즘이 데이터 셋의 사이즈가 증가할수록 정확도가 증가하는 것을 볼 수 있다.

확실히 큰 데이터 셋을 사용하는 것이 알고리즘의 정확도 향상에 큰 도움을 주는 것은 맞지만 앞의 강의에서 배웠듯이 낮은 편향에서는 데이터 셋 크기를 늘려도 그다지 효과가 없을 수도 있다. 따라서 이를 먼저 판단해야 한다. 어떤 가설이 피쳐가 충분한지 확인하는 가장 좋은 방법은 해당 피쳐로 사람이 문제를 해결할 수 있는지 보는 것이다. 예를 들어서 집 사이즈 하나만으로 사람이 집 가격을 예측할 수 있기는 어려울 것이므로 피쳐가 부족하다고 볼 수 있다. 

즉 요약하면 파라미터가 많은 낮은 편향 모델에 대해서 더 많은 데이터로 학습시킬수록 더 좋은 정확도를 얻을 수 있다.